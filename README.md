# ğŸŒŸ Maze Simulator

Bem-vindo ao Maze Simulator! Este projeto Ã© um simulador interativo onde ratos ğŸ­ tentam encontrar um pedaÃ§o de queijo ğŸ§€ em um labirinto complexo. Aprenda sobre algoritmos de busca e veja-os em aÃ§Ã£o neste divertido e educativo simulador.

## ğŸš€ Funcionalidades
GeraÃ§Ã£o AutomÃ¡tica de Labirintos: Cada sessÃ£o comeÃ§a com um novo labirinto, gerado aleatoriamente.
SimulaÃ§Ã£o de Busca: Ratos virtuais usam o algoritmo de busca em largura (BFS) para encontrar o caminho atÃ© o queijo.
Interface GrÃ¡fica: Visualize todo o processo em uma interface grÃ¡fica amigÃ¡vel.
## ğŸ“‹ PrÃ©-requisitos
> Antes de iniciar, certifique-se de ter instalado:

- Java JDK 11 ou superior
- IDE com suporte para Java (recomendado: IntelliJ IDEA ou Eclipse)
## ğŸ› ï¸ InstalaÃ§Ã£o
> Clone o repositÃ³rio para sua mÃ¡quina local usando:

```bash
Copy code
git clone https://github.com/seuusuario/maze-simulator.git
```
## âš™ï¸ Como Usar
> Para iniciar o simulador, navegue atÃ© o diretÃ³rio do projeto e execute:

```bash
Copy code
java -jar MazeSimulator.jar
```
## ğŸ§  Algoritmos Utilizados
- Busca em Largura (BFS): Garante que encontraremos o caminho mais curto para o queijo, se houver um caminho disponÃ­vel.
- GeraÃ§Ã£o de Labirintos: Utiliza uma adaptaÃ§Ã£o do algoritmo de Prim para criar labirintos complexos e solucionÃ¡veis.
## ğŸ“Š Melhorias Futuras
> - ImplementaÃ§Ã£o de outros algoritmos de busca como A* ou Dijkstra.
> - AdiÃ§Ã£o de nÃ­veis de dificuldade com labirintos maiores ou mÃºltiplos ratos.
> - Recursos de pausa e reinÃ­cio durante a simulaÃ§Ã£o.
> -  ImplementaÃ§Ã£o do Deep Q Learning (DQL): A aplicaÃ§Ã£o de DQL pode trazer melhorias significativas no comportamento dos ratos virtuais ao permitir que aprendam a maximizar uma recompensa cumulativa atravÃ©s do tempo. 
> -  Veja como isso pode beneficiar o projeto:
>     1) Aprendizado por ReforÃ§o: O DQL permite que os agentes aprendam de forma mais eficiente a encontrar o queijo, evitando caminhos subÃ³timos.
>     2) AdaptaÃ§Ã£o a Ambientes Complexos: O algoritmo Ã© robusto o suficiente para lidar com ambientes dinÃ¢micos e complexos, onde decisÃµes sÃ£o tomadas com base em percepÃ§Ãµes limitadas.
>     3) DecisÃµes Baseadas em Estado: O rato poderia aprender a tomar decisÃµes considerando o estado completo do ambiente, o que inclui a localizaÃ§Ã£o do queijo e a configuraÃ§Ã£o de obstÃ¡culos e penalidades.
## ğŸ¤ ContribuiÃ§Ãµes
### ContribuiÃ§Ãµes sÃ£o sempre bem-vindas! Para contribuir:

## Fork o projeto
- Crie sua Feature Branch (```git checkout -b feature/AmazingFeature```)
- FaÃ§a commit de suas mudanÃ§as (```git commit -m 'Add some AmazingFeature'```)
- FaÃ§a push para a Branch (```git push origin feature/AmazingFeature```)
- Abra um Pull Request
## ğŸ“ LicenÃ§a
DistribuÃ­do sob a licenÃ§a MIT. Veja LICENSE para mais informaÃ§Ãµes.

## ğŸ“ Contato
Wemerson Nino â€“ @wemersonnino

### Link do Projeto: https://github.com/wemersonnino/labirinto-ratos
